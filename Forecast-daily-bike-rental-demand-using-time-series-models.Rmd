---
title: "Forecast daily bike rental demand using time series models"
author: "Hitesh Kumar /jaiswal"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

# About Data Analysis Report

This RMarkdown file contains the report of the data analysis done for the project on forecasting daily bike rental demand using time series models in R. It contains analysis such as data exploration, summary statistics and building the time series models. The final report was completed on `r date()`. 

**Data Description:**

This dataset contains the daily count of rental bike transactions between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.

**Data Source:** https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset

**Relevant Paper:** 

Fanaee-T, Hadi, and Gama, Joao. Event labeling combining ensemble detectors and background knowledge, Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg



# Task 1: Load and explore the data
# Task 1.1 Loading Data in R Studio
data1 <- read.csv("C:/Users/ASUS/Downloads/Project/hour.csv", header=TRUE, stringsAsFactors=FALSE)
data2 <- read.csv("C:/Users/ASUS/Downloads/Project/day.csv", header=TRUE, stringsAsFactors=FALSE)
dim(data1)    # dimension of data1
dim(data2)    # dimension of data2
# minimum and maximum value
min(data2[,2], na.rm=T)  # minimum value 
max(data2[,2], na.rm=T)   # maximum value

min(data2[,16], na.rm=T) # minimum value
max(data2[,16], na.rm=T)   # maximum value

# Task 1.2 Load data and install packages
For Summarisation of Data
pivottabler
library(pivottabler)
install.packages('pivottabler')


# Task 1.3 Exploring data in R Studio

library(pivottabler)

# Task 1.3.1 Summary of events based on Month Name/Year
library(pivottabler)
pt <- PivotTable$new()
pt$addData(data1)
pt$addColumnDataGroups("mnth.name")
pt$addRowDataGroups("year")
pt$defineCalculation(calculationName="cnt", summariseExpression="n()")
pt$evaluatePivot()
pt

# Or using Quickpivot
library(pivottabler)
pt <- qpvt(data1, "mnth.name", "year", "n()")
pt


# Task 1.3.2 Summary of events based on Years /Seasons
library(pivottabler)
pt1 <- PivotTable$new()
pt1$addData(data1)
pt1$addColumnDataGroups("year")
pt1$addRowDataGroups("Season.Name")
pt1$defineCalculation(calculationName="cnt", summariseExpression="n()")
pt1$evaluatePivot()
pt1

# Or using Quickpivot
library(pivottabler)
pt1 <- qpvt(data1, "Season.Name", "year", "n()")
pt1


# Task 1.3.3 Month Wise Yearly Transction
library(pivottabler)
pt2 <- qpvt(data1, "mnth.name", "year", "sum(cnt)")
pt2

# Task 1.3.4 Season Wise Yearly Transaction
library(pivottabler)
pt3 <- qpvt(data1, "Season.Name", "year", "sum(cnt)")
pt3


# Task Two: Fit and forecast time series data using ARIMA models
#2.1:- import the data

data2 <- read.csv("C:/Users/ASUS/Downloads/Project/day.csv", header=TRUE, stringsAsFactors=FALSE)

#2.2:-attach the data
attach(data2)

#2.3:-Package required:-tseries, forecast
install.packages("tseries")
install.packages("forecast")

#2.4:-Library
library(tseries)
library(forecast)

#2.5:-Apply to check the stationaraty

#1. plot first to check whether the data is Stationary
plot.ts(cnt)
adf.test(cnt)     # pvalue is greater than 5% level of Significance data is not stationary

#2.convert the datainto stationary data for time Series analysis
rncnt=diff(log(cnt))
plot.ts(rncnt)
adf.test(rncnt)   # now pvalue is less than 5% level of Significance data is now stationary

#2.6:-apply auto.arima to check best fit model
auto.arima(rncnt)

#2.7:-Create a model
modelrncnt=arima(rncnt,order=c(2,0,1))
modelrncnt

#2.8 :-Diagnostic Check
dc=residuals(modelrncnt)
acf(dc)
plot.ts(dc)           # Graph of residuals
gghistogram(dc)       # here we can see the histogram is bell shaped & normally distributed
Box.test(dc,lag=10,type=c("Box-Pierce","Ljung-Box"),fitdf=0)































